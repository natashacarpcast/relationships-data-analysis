{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed tutorial from https://colab.research.google.com/github/maobedkova/TopicModelling_PySpark_SparkNLP/blob/master/Topic_Modelling_with_PySpark_and_Spark_NLP.ipynb#scrollTo=XwOdzQ_PAJi0\n",
    " \n",
    "Also, reviewed SparkNLP documentation to understand each step more deeply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.jars.packages': 'com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.1', 'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.jars.packages\": \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.1\",\n",
    "        \"spark.pyspark.python\": \"python3\",\n",
    "        \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "        \"spark.pyspark.virtualenv.type\": \"native\",\n",
    "        \"spark.pyspark.virtualenv.bin.path\": \"/usr/bin/virtualenv\"\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1716401927822_0004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-37-116.ec2.internal:20888/proxy/application_1716401927822_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-33-203.ec2.internal:8042/node/containerlogs/container_1716401927822_0004_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spark-nlp\n",
      "  Using cached https://files.pythonhosted.org/packages/13/96/a580e098e00905ef715253fc85589db00ca5bfa324deb5aa7cb4fc069004/spark_nlp-5.3.3-py2.py3-none-any.whl\n",
      "Installing collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-5.3.3"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package('spark-nlp',\"https://pypi.org/simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'18971M'"
     ]
    }
   ],
   "source": [
    "#Ensure executers are using enough memory\n",
    "sc._conf.get('spark.executor.memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.sql import types as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3://finalproject-nat-s3/prepared-data/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns: 11\n",
      "Total Rows: 1646407\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- created: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- num_comments: string (nullable = true)\n",
      " |-- entire_text: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- person_1: string (nullable = true)\n",
      " |-- person_2: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "#Recall structure of the dataframe \n",
    "print('Total Columns: %d' % len(df.dtypes))\n",
    "print('Total Rows: %d' % df.count())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+-----+--------------------+--------------------+------------+--------------------+----+--------+--------+\n",
      "|     id|         created|              author|score|               title|            selftext|num_comments|         entire_text|year|person_1|person_2|\n",
      "+-------+----------------+--------------------+-----+--------------------+--------------------+------------+--------------------+----+--------+--------+\n",
      "| kj1flj|2020-12-23 15:12|    u/throwaway_135i|    2|I 20M am moving 1...|Hey rrelationship...|          13|i 20m am moving 1...|2020|        |        |\n",
      "| qoi622|2021-11-07 00:40|           u/fatiabs|    7|My parents 45F 56...|I 22F have had a ...|           3|my parents 45f 56...|2021|      45|      56|\n",
      "| 1kbqs9|2013-08-13 22:28|         u/[deleted]|    2|My 19F mom caught...|Hello   So this m...|           6|my 19f mom caught...|2013|        |        |\n",
      "| gwqxas|2020-06-04 16:41|u/ThrowRAmattmurdock|    1|I22M am having do...|I want to apologi...|           0|i22m am having do...|2020|        |        |\n",
      "| 9az7r0|2018-08-28 09:07|           u/bikefun|   13|My fiance says he...|There are a lot o...|          17|my fiance says he...|2018|        |        |\n",
      "|14x26r8|2023-07-11 15:16|u/ThrowRASuitCout635|    1|My F18 girlfriend...|My F18 girlfriend...|           1|my f18 girlfriend...|2023|        |        |\n",
      "| cdu8q4|2019-07-16 03:19|  u/katn1ss_everdeen|    1|      I feel TRAPPED|How do I break up...|           6|i feel trappedhow...|2019|        |        |\n",
      "| 9xcwsj|2018-11-15 10:53|       u/Alphacademy|    3|My girlfriend 18F...|We have been dati...|          19|my girlfriend 18f...|2018|        |        |\n",
      "| g0iher|2020-04-13 08:00|    u/WhatTheFuckSam|    1|My 24M girlfriend...|This just happene...|           9|my 24m girlfriend...|2020|        |        |\n",
      "|15uu29l|2023-08-18 14:36|u/LettuceDramatic...|    1|Is myF22 boyfrien...|Me22f and my boyf...|           1|is myf22 boyfrien...|2023|        |        |\n",
      "+-------+----------------+--------------------+-----+--------------------+--------------------+------------+--------------------+----+--------+--------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "#Recall structure of the dataframe \n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start with DocumentAssembler --> This prepares the data into a format that \n",
    "#SparkNLP can understand\n",
    "\n",
    "#https://sparknlp.org/api/com/johnsnowlabs/nlp/DocumentAssembler\n",
    "\n",
    "documentAssembler_text = DocumentAssembler()\\\n",
    "     .setInputCol(\"entire_text\")\\\n",
    "     .setOutputCol('document_text')\n",
    "\n",
    "#documentAssembler_title = DocumentAssembler()\\\n",
    "     #.setInputCol(\"title\")\\\n",
    "     #.setOutputCol('document_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenizer --> Separates sentence into words\n",
    "\n",
    "#https://sparknlp.org/api/com/johnsnowlabs/nlp/annotators/Tokenizer.html\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "            .setInputCols(['document_text'])\\\n",
    "            .setOutputCol('tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizer --> cleans the tokens \n",
    "\n",
    "#https://sparknlp.org/docs/en/annotators#normalizer\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['tokenized']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]"
     ]
    }
   ],
   "source": [
    "#Lemmatizer --> converts words of the same family into a common root word. SparkNLP\n",
    "#provides an already pretrained lemmatization model\n",
    "\n",
    "#https://sparknlp.org/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('lemmatized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Stop words\n",
    "#Asked ChatGPT for a list mentioning that there are a lot of submissions that \n",
    "#have abbreviated words like didn't, etc. but without the apostrophe\n",
    "\n",
    "stop_words = [\n",
    "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \n",
    "    \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \n",
    "    \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n",
    "    \"did\", \"doing\", \"will\", \"would\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"shall\", \"ought\", \"about\", \"above\", \"across\", \"after\", \n",
    "    \"against\", \"along\", \"amid\", \"among\", \"around\", \"as\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\", \"between\", \"beyond\", \"but\", \n",
    "    \"by\", \"concerning\", \"considering\", \"despite\", \"down\", \"during\", \"except\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"near\", \"next\", \n",
    "    \"notwithstanding\", \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"out\", \"outside\", \"over\", \"past\", \"regarding\", \"round\", \"since\", \"than\", \"through\", \n",
    "    \"throughout\", \"till\", \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\", \"up\", \"upon\", \"versus\", \"via\", \"with\", \"within\", \n",
    "    \"without\", \"cant\", \"cannot\", \"couldve\", \"couldnt\", \"didnt\", \"doesnt\", \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"hed\", \"hell\", \"hes\", \"howd\", \n",
    "    \"howll\", \"hows\", \"id\", \"ill\", \"im\", \"ive\", \"isnt\", \"itd\", \"itll\", \"its\", \"lets\", \"mightve\", \"mustve\", \"mustnt\", \"shant\", \"shed\", \"shell\", \n",
    "    \"shes\", \"shouldve\", \"shouldnt\", \"thatll\", \"thats\", \"thered\", \"therell\", \"therere\", \"theres\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"wed\", \n",
    "    \"well\", \"were\", \"weve\", \"werent\", \"whatd\", \"whatll\", \"whatre\", \"whats\", \"whatve\", \"whend\", \"whenll\", \"whens\", \"whered\", \"wherell\", \"wheres\", \n",
    "    \"whichd\", \"whichll\", \"whichre\", \"whichs\", \"whod\", \"wholl\", \"whore\", \"whos\", \"whove\", \"whyd\", \"whyll\", \"whys\", \"wont\", \"wouldve\", \"wouldnt\", \n",
    "    \"youd\", \"youll\", \"youre\", \"youve\", \"f\", \"m\", \"relationship\", \"because\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sparknlp.annotator import StopWordsCleaner\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemmatized']) \\\n",
    "     .setOutputCol('cleaned_words') \\\n",
    "     .setStopWords(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finisher --> converts the cleaned words into a format easier to use\n",
    "\n",
    "#https://sparknlp.org/api/python/reference/autosummary/sparknlp/base/finisher/index.html\n",
    "\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['cleaned_words']) \\\n",
    "     .setOutputCols(\"finished_tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now, put everything together to create a pipeline that processes the text.\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "     .setStages([documentAssembler_text,                  \n",
    "                 tokenizer,\n",
    "                 normalizer,                  \n",
    "                 lemmatizer,                  \n",
    "                 stopwords_cleaner, \n",
    "                 finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: string, created: string, author: string, score: string, title: string, selftext: string, num_comments: string, entire_text: string, year: int, person_1: string, person_2: string, finished_tokens: array<string>]"
     ]
    }
   ],
   "source": [
    "#Now, apply pipeline to the data to transform it in the needed way for the LDA\n",
    "\n",
    "processed_text = pipeline.fit(df).transform(df)\n",
    "processed_text.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageLevel(True, True, False, False, 1)"
     ]
    }
   ],
   "source": [
    "#Ensure that dataframe is persisted in memory\n",
    "processed_text.storageLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization \n",
    "\n",
    "In this next step, I'll count the frequency for each word and perform a TF-IDF measure, to be able to identify which words are really salient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfizer = CountVectorizer(inputCol='finished_tokens', outputCol='terms_frequencies', minDF=0.01, maxDF=0.80)\n",
    "tf_model = tfizer.fit(processed_text)\n",
    "tf_result = tf_model.transform(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: string, created: string, author: string, score: string, title: string, selftext: string, num_comments: string, entire_text: string, year: int, person_1: string, person_2: string, finished_tokens: array<string>]"
     ]
    }
   ],
   "source": [
    "processed_text.unpersist() #Unpersist to release memory and persist another df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idfizer = IDF(inputCol='terms_frequencies', outputCol='tf_idf_features')\n",
    "idf_model = idfizer.fit(tf_result)\n",
    "tfidf_result = idf_model.transform(tf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: string, created: string, author: string, score: string, title: string, selftext: string, num_comments: string, entire_text: string, year: int, person_1: string, person_2: string, finished_tokens: array<string>, terms_frequencies: vector, tf_idf_features: vector]"
     ]
    }
   ],
   "source": [
    "tfidf_result.persist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_topics = 15 \n",
    "max_iter = 10\n",
    "\n",
    "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features', seed=25)\n",
    "lda_model = lda.fit(tfidf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: string, created: string, author: string, score: string, title: string, selftext: string, num_comments: string, entire_text: string, year: int, person_1: string, person_2: string, finished_tokens: array<string>, terms_frequencies: vector, tf_idf_features: vector]"
     ]
    }
   ],
   "source": [
    "tfidf_result.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This code is copied from the tutorial https://colab.research.google.com/github/maobedkova/TopicModelling_PySpark_SparkNLP/blob/master/Topic_Modelling_with_PySpark_and_Spark_NLP.ipynb#scrollTo=XwOdzQ_PAJi0\n",
    "\n",
    "vocab = tf_model.vocabulary\n",
    "\n",
    "def get_words(token_list):\n",
    "     return [vocab[token_id] for token_id in token_list]\n",
    "       \n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------------------+\n",
      "|topic|                                                                 topicWords|\n",
      "+-----+---------------------------------------------------------------------------+\n",
      "|    0|    [love, ex, break, feel, cheat, hurt, boyfriend, bad, issue, girlfriend]|\n",
      "|    1|            [porn, wedding, u, ring, say, fight, drink, tell, thing, watch]|\n",
      "|    2|            [block, ex, friend, fuck, tell, gf, back, message, then, break]|\n",
      "|    3|           [ampxb, people, friend, woman, man, guy, very, make, girl, feel]|\n",
      "|    4|                 [say, tell, then, day, night, ask, go, drink, party, home]|\n",
      "|    5|               [dog, fiancé, sleep, cat, call, wake, bed, room, lie, phone]|\n",
      "|    6|      [husband, partner, kid, marry, son, marriage, work, child, job, live]|\n",
      "|    7|       [brother, game, play, birthday, drug, parent, gift, video, pay, day]|\n",
      "|    8|       [friend, girl, feelings, date, crush, love, guy, really, feel, each]|\n",
      "|    9|           [money, pay, roommate, job, drink, buy, work, move, live, house]|\n",
      "|   10|  [message, phone, picture, send, cheat, wife, post, account, delete, girl]|\n",
      "|   11|[mom, dad, sister, mother, parent, family, daughter, father, brother, baby]|\n",
      "|   12| [friend, school, college, distance, move, b, group, each, break, together]|\n",
      "|   13|      [ex, coworker, text, conversation, ask, friend, talk, date, guy, say]|\n",
      "|   14|             [sex, amp, wife, clean, wear, initiate, work, eat, cook, time]|\n",
      "+-----+---------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "#This code is copied from the tutorial https://colab.research.google.com/github/maobedkova/TopicModelling_PySpark_SparkNLP/blob/master/Topic_Modelling_with_PySpark_and_Spark_NLP.ipynb#scrollTo=XwOdzQ_PAJi0\n",
    "num_top_words = 10\n",
    "\n",
    "topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "topics.select('topic', 'topicWords').show(truncate=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column with topic distribution for each submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topicDistribution                                                                                                                                                                                                                                                                                                         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[2.390090226125229E-4,2.3245682967455535E-4,2.302209609259938E-4,2.34072258272865E-4,2.332100439012342E-4,2.3096974748248333E-4,0.2809287789825075,2.2933110288295703E-4,2.4218203046996338E-4,0.23140125229290265,2.328475659981163E-4,0.056708214487256076,0.29087118060738426,2.338143094833706E-4,0.13775245975824538]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "# Transform data to get topic distributions\n",
    "df_with_lda = lda_model.transform(tfidf_result)\n",
    "\n",
    "df_with_lda.select(\"topicDistribution\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_repartitioned = df_with_lda.repartition(10)\n",
    "df_repartitioned.write.parquet(\"s3://finalproject-nat-s3/data_withtopics\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of topics\n",
    "\n",
    "Some topics seem reasonable and easier to interpret, whereas other ones are vague. I wish I could have fine tuned more the model using performance metrics, but the limitation of resources made the modeling very slow and it reached a point where I was not able to invest more time fine-tuning it. \n",
    "\n",
    "Therefore, I've decided to advance the analysis with the available data, stick to the reasonable topics and categorize the rest as \"Unclear\". \n",
    "\n",
    "The topics I'll use for further analysis are labeled as following:\n",
    "\n",
    "- Topic 0: Romantic relationships \n",
    "- Topic 8: Dating\n",
    "- Topic 9: Finances, employment and housing\n",
    "- Topic 10: Social media and messaging\n",
    "- Topic 11: Family\n",
    "\n",
    "P.D. Although topic 6 seems to be about marriage and kids, after exploring different text samples I came to the conclusion that it is not a coherent category and therefore, I'll label it as unclear as well. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
